{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afadc79",
   "metadata": {},
   "source": [
    "# Features 2\n",
    "Acá probamos diferentes modelos para las features 2.\n",
    "|hora|dia_semana|mes|es_feriado|total_bicis_salieron_global|pct_mujeres_salieron_global|pct_hombres_salieron_global|q1_edad_salieron_global|media_edad_salieron_global|q3_edad_salieron_global|pct_iconic_salieron_global|pct_fit_salieron_global|bicis_salieron_estacion_2| ... | bicis_salieron_estacion_x|llegadas_estacion_2_h1| ...|llegadas_estacion_x_h24|target_estacion_2| ... |target_estacion_x|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d1edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edf31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_f2 as md2\n",
    "import data_processing_f2 as dp\n",
    "import metrics as mt\n",
    "import visualizacion_f2 as vis2\n",
    "import auxiliares_f2 as aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfca353",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "train_f2_path = os.path.join(BASE_DIR, '..', '..', 'data', 'processed', 'features2', 'train_dataset_features2.csv')\n",
    "val_f2_path = os.path.join(BASE_DIR, '..', '..', 'data', 'processed', 'features2', 'val_dataset_features2.csv')\n",
    "test_f2_path = os.path.join(BASE_DIR, '..', '..','data', 'processed', 'features2', 'test_dataset_features2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2650e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f2 = pd.read_csv(train_f2_path)\n",
    "val_f2 = pd.read_csv(val_f2_path)\n",
    "test_f2 = pd.read_csv(test_f2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4626ecd1",
   "metadata": {},
   "source": [
    "# Modelos básicos\n",
    "Corremos modelos básicos con hiperparámetros arbitrarios para ver como es la situación actual. Mostramos para cada modelo las métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792331fa",
   "metadata": {},
   "source": [
    "## 1. Entrenamiento por separado\n",
    "- solo con si mismas (para cada una)\n",
    "- cada una entrenada por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dp)\n",
    "targets =  dp.obtener_targets_disponibles(train_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_all = []\n",
    "lin_reg_true = []\n",
    "importlib.reload(md2)\n",
    "importlib.reload(dp)\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Training Linear Regression for station {targets[i]}...\")\n",
    "    df_filtrado_train = dp.filtrar_dataset_por_estaciones(train_f2, [targets[i]], verbose=False)\n",
    "    X_train, y_train, feature_names_train = dp.dividir_dataset_estacion(df_filtrado_train, targets[i], verbose=False)\n",
    "    \n",
    "    df_filtrado_val = dp.filtrar_dataset_por_estaciones(val_f2, [targets[i]], verbose=False)\n",
    "    X_val, y_val, feature_names_val = dp.dividir_dataset_estacion(df_filtrado_val, targets[i], verbose=False)\n",
    "    lin_reg_true.append(y_val)\n",
    "    \n",
    "    pred = md2.linear_regression(X_train, y_train, X_val)\n",
    "    lin_reg_all.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mt)\n",
    "mt.estadisticas_metricas_por_estacion(lin_reg_true, lin_reg_all, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb9b14",
   "metadata": {},
   "source": [
    "# Visualización de las features 2\n",
    "Hacemos PCA y visualizamos, imprimimos estadísticas descriptivas y graficamos las distribuciones de las features. Cualquier cosa que ayude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9945a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c169d16",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Acomodamos features, relacionamos, sacamos, reducimos la dimensionalidad, etc. para mejorar el modelo en base a lo que vimos en la visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70e52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b332eb92",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "Elegimos los óptimos hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9709aa8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a07cdc8",
   "metadata": {},
   "source": [
    "# Entrenamientos finales\n",
    "Entrenamos los modelos finales con los hiperparámetros óptimos y guardamos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f9c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
