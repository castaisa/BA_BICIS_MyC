# Regresion lineal
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from sklearn.model_selection import train_test_split
# Importar m√°s modelos
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import ElasticNet
import numpy as np


# Agregar despu√©s del c√≥digo existente
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score
from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor, BaggingRegressor
from sklearn.linear_model import HuberRegressor, TheilSenRegressor, RANSACRegressor
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.ensemble import VotingRegressor, StackingRegressor
import time
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import ParameterGrid


ds_14 = pd.read_csv('data/processed/dataset_14.csv')



#Elimino las columnas fecha y fecha y hora
ds_14 = ds_14.drop(columns=['fecha', 'fecha_hora'])


# Separar features (X) y target (y)
ds_y = ds_14['target']
ds_X = ds_14.drop(columns=['target'])

# Dividir en train y validation (80% train, 20% validation)
X_train, X_val, y_train, y_val = train_test_split(
    ds_X, ds_y, 
    test_size=0.2, 
    random_state=13,
    shuffle=False
)

#El mejor modelo fue gradient boosting, probamos muchos hiperparametros por ahi
print("\n" + "="*80)
print("üîç GRID SEARCH EXHAUSTIVO PARA GRADIENT BOOSTING")
print("="*80)

# Definir una grilla muy completa de hiperpar√°metros
gb_param_grid = {
    'n_estimators': [50, 100, 150, 200, 250, 300],
    'learning_rate': [0.01, 0.05],
    'max_depth': [3, 4, 5],
    'min_samples_split': [2, 5, 10, 15, 20],
    'min_samples_leaf': [1, 2, 4, 6, 8],
    'max_features': ['sqrt', 'log2', None, 0.5, 0.7],
    'subsample': [0.8, 0.85, 0.9, 0.95, 1.0],
    'loss': ['squared_error', 'absolute_error', 'huber']
}

total_combinations = (len(gb_param_grid['n_estimators']) * len(gb_param_grid['learning_rate']) * 
                     len(gb_param_grid['max_depth']) * len(gb_param_grid['min_samples_split']) * 
                     len(gb_param_grid['min_samples_leaf']) * len(gb_param_grid['max_features']) * 
                     len(gb_param_grid['subsample']) * len(gb_param_grid['loss']))

print(f"üî¢ Combinaciones totales a probar: {total_combinations:,}")
print("‚ö†Ô∏è  Esto puede tomar mucho tiempo. Usando paralelizaci√≥n...")

# Crear el modelo base
gb_base = GradientBoostingRegressor(random_state=13, validation_fraction=0.1, n_iter_no_change=10)

# Clase personalizada para mostrar progreso
class VerboseGridSearchCV(GridSearchCV):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.combination_count = 0
        self.total_combinations = 0
        
    def fit(self, X, y=None):
        # Calcular total de combinaciones
        self.total_combinations = len(list(ParameterGrid(self.param_grid)))
        print(f"üìä Total de combinaciones a evaluar: {self.total_combinations}")
        print(f"üìä Con {self.cv} folds de CV = {self.total_combinations * self.cv} entrenamientos")
        print("\nüöÄ Iniciando evaluaci√≥n de hiperpar√°metros...")
        print("-" * 80)
        
        return super().fit(X, y)

# Grid Search con CV y progreso personalizado
print("\nüöÄ Iniciando Grid Search...")
start_time = time.time()

# Crear un callback para mostrar progreso
class ProgressCallback:
    def __init__(self, total_combinations):
        self.total_combinations = total_combinations
        self.completed = 0
        self.best_score = -float('inf')
        self.best_params = None
        
    def update(self, score, params):
        self.completed += 1
        if score > self.best_score:
            self.best_score = score
            self.best_params = params
            
        if self.completed % 50 == 0 or score > self.best_score:
            percentage = (self.completed / self.total_combinations) * 100
            print(f"üìà Progreso: {self.completed}/{self.total_combinations} ({percentage:.1f}%) - "
                  f"Mejor R¬≤: {self.best_score:.4f}")
            if score > self.best_score - 0.001:  # Mostrar par√°metros prometedores
                print(f"   Par√°metros actuales: {params}")

gb_grid_search = GridSearchCV(
    estimator=gb_base,
    param_grid=gb_param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,  # Usar todos los procesadores disponibles
    verbose=2,  # Nivel m√°ximo de verbosidad
    return_train_score=True
)

# Mostrar par√°metros que se van a probar
print(f"\nüìã RANGO DE HIPERPAR√ÅMETROS A PROBAR:")
for param, values in gb_param_grid.items():
    print(f"   {param}: {values}")

print(f"\n‚è∞ Hora de inicio: {time.strftime('%H:%M:%S')}")
print("üîÑ Iniciando b√∫squeda exhaustiva...")

# Entrenar con monitoreo de progreso
gb_grid_search.fit(X_train, y_train)

elapsed_time = time.time() - start_time
print(f"\n‚è±Ô∏è  Grid Search completado en {elapsed_time/60:.1f} minutos")
print(f"‚è∞ Hora de finalizaci√≥n: {time.strftime('%H:%M:%S')}")

# Obtener el mejor modelo
best_gb_model = gb_grid_search.best_estimator_
best_gb_params = gb_grid_search.best_params_
best_cv_score = gb_grid_search.best_score_

print(f"\nüèÜ MEJORES HIPERPAR√ÅMETROS ENCONTRADOS:")
for param, value in best_gb_params.items():
    print(f"   {param}: {value}")

print(f"\nüìä MEJOR SCORE CV: {best_cv_score:.6f}")

# Mostrar progreso de los mejores resultados durante la b√∫squeda
print(f"\nüìà HIST√ìRICO DE MEJORES RESULTADOS:")
results_df = pd.DataFrame(gb_grid_search.cv_results_)
results_df_sorted = results_df.sort_values('mean_test_score', ascending=False)

print("Rank  R¬≤ Score    Par√°metros")
print("-" * 100)
for i, (idx, row) in enumerate(results_df_sorted.head(10).iterrows()):
    params_short = {k.replace('param_', ''): v for k, v in row.items() if k.startswith('param_')}
    params_str = ", ".join([f"{k}:{v}" for k, v in list(params_short.items())[:4]])  # Primeros 4 par√°metros
    print(f"{i+1:4d}  {row['mean_test_score']:8.4f}    {params_str}...")

# Evaluar en el conjunto de validaci√≥n
best_gb_pred = best_gb_model.predict(X_val)
best_gb_r2 = r2_score(y_val, best_gb_pred)
best_gb_mse = mean_squared_error(y_val, best_gb_pred)
best_gb_rmse = root_mean_squared_error(y_val, best_gb_pred)
best_gb_mae = mean_absolute_error(y_val, best_gb_pred)
best_gb_mape = mean_absolute_percentage_error(y_val, best_gb_pred)

print(f"\nüéØ RESULTADOS EN CONJUNTO DE VALIDACI√ìN:")
print(f"   R¬≤: {best_gb_r2:.6f}")
print(f"   MSE: {best_gb_mse:.6f}")
print(f"   RMSE: {best_gb_rmse:.6f}")
print(f"   MAE: {best_gb_mae:.6f}")
print(f"   MAPE: {best_gb_mape:.6f}")

# Comparar con el modelo original
original_gb = GradientBoostingRegressor(n_estimators=100, random_state=13, max_depth=6)
original_gb.fit(X_train, y_train)
original_gb_pred = original_gb.predict(X_val)
original_gb_r2 = r2_score(y_val, original_gb_pred)

improvement = ((best_gb_r2 - original_gb_r2) / abs(original_gb_r2)) * 100
print(f"\nüìà MEJORA RESPECTO AL MODELO ORIGINAL:")
print(f"   Modelo original R¬≤: {original_gb_r2:.6f}")
print(f"   Modelo optimizado R¬≤: {best_gb_r2:.6f}")
print(f"   Mejora: {improvement:.2f}%")

# Informaci√≥n adicional del modelo
print(f"\nüîç INFORMACI√ìN ADICIONAL DEL MEJOR MODELO:")
print(f"   N√∫mero de √°rboles: {best_gb_model.n_estimators}")
print(f"   Tasa de aprendizaje: {best_gb_model.learning_rate}")
print(f"   Profundidad m√°xima: {best_gb_model.max_depth}")
print(f"   Funci√≥n de p√©rdida: {best_gb_model.loss}")
print(f"   Submuestreo: {best_gb_model.subsample}")
print(f"   Min samples split: {best_gb_model.min_samples_split}")
print(f"   Min samples leaf: {best_gb_model.min_samples_leaf}")
print(f"   Max features: {best_gb_model.max_features}")

# Feature importance del mejor modelo
print(f"\nüéØ TOP 15 FEATURES M√ÅS IMPORTANTES (Mejor Gradient Boosting):")
feature_names = X_train.columns
gb_importances = best_gb_model.feature_importances_
top_features = sorted(zip(feature_names, gb_importances), key=lambda x: x[1], reverse=True)[:15]
for i, (feature, importance) in enumerate(top_features):
    print(f"   {i+1:2d}. {feature}: {importance:.4f}")

# An√°lisis de los resultados del Grid Search
print(f"\nüìä AN√ÅLISIS DE RESULTADOS DEL GRID SEARCH:")
results_df = pd.DataFrame(gb_grid_search.cv_results_)

print(f"   Total de combinaciones probadas: {len(results_df)}")
print(f"   Mejor ranking: {results_df['rank_test_score'].min()}")
print(f"   Score promedio: {results_df['mean_test_score'].mean():.4f}")
print(f"   Desviaci√≥n est√°ndar promedio: {results_df['std_test_score'].mean():.4f}")
print(f"   Tiempo promedio por combinaci√≥n: {elapsed_time/len(results_df):.2f} segundos")

# Top 10 combinaciones con m√°s detalle
print(f"\nüèÖ TOP 10 MEJORES COMBINACIONES:")
top_10_results = results_df.nlargest(10, 'mean_test_score')
for i, (idx, row) in enumerate(top_10_results.iterrows()):
    print(f"\n   {i+1:2d}. R¬≤ = {row['mean_test_score']:.6f} (¬±{row['std_test_score']:.4f})")
    print(f"       Tiempo: {row['mean_fit_time']:.2f}s")
    
    # Mostrar todos los par√°metros
    params = {k.replace('param_', ''): v for k, v in row.items() if k.startswith('param_')}
    for param, value in params.items():
        print(f"       {param}: {value}")

# An√°lisis de sensibilidad de par√°metros
print(f"\nüîç AN√ÅLISIS DE SENSIBILIDAD DE PAR√ÅMETROS:")
for param in gb_param_grid.keys():
    param_col = f'param_{param}'
    if param_col in results_df.columns:
        param_analysis = results_df.groupby(param_col)['mean_test_score'].agg(['mean', 'std', 'count'])
        print(f"\n   {param}:")
        for value, stats in param_analysis.iterrows():
            print(f"      {value}: R¬≤ = {stats['mean']:.4f} (¬±{stats['std']:.4f}, n={stats['count']})")

# Guardar el mejor modelo para uso futuro
print(f"\nüíæ El mejor modelo Gradient Boosting ha sido entrenado y est√° listo para usar")
print(f"   Acceder al modelo: best_gb_model")
print(f"   Predicciones: best_gb_pred")


# Combinar todos los resultados
all_final_results = []


# Comparaci√≥n final con todos los modelos anteriores
print(f"\nüèÜ COMPARACI√ìN CON TODOS LOS MODELOS ANTERIORES:")
print(f"   Mejor modelo anterior: {all_final_results[0]['name']} (R¬≤ = {all_final_results[0]['r2']:.6f})")
print(f"   Gradient Boosting optimizado: R¬≤ = {best_gb_r2:.6f}")

if best_gb_r2 > all_final_results[0]['r2']:
    final_improvement = ((best_gb_r2 - all_final_results[0]['r2']) / abs(all_final_results[0]['r2'])) * 100
    print(f"   üéâ ¬°NUEVO CAMPE√ìN! Mejora de {final_improvement:.2f}%")
else:
    print(f"   üìä El modelo anterior sigue siendo mejor")

print(f"\n‚ú® Grid Search exhaustivo completado exitosamente!")
print(f"üìä Estad√≠sticas finales:")
print(f"   - Tiempo total: {elapsed_time/60:.1f} minutos")
print(f"   - Combinaciones probadas: {len(results_df):,}")
print(f"   - Entrenamientos realizados: {len(results_df) * 5:,}")
print(f"   - Mejor R¬≤ encontrado: {best_cv_score:.6f}")